{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21-01 주제분석 3주차 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주제분석 3주차 분석 툴은 Python/R 둘 다 가능합니다. \n",
    "    - 1-3주차 패키지 문제의 조건 및 힌트는 Python을 기준으로 하지만, R을 사용해도 무방합니다.\n",
    "    - 다만 2/3주차의 머신러닝/딥러닝 모듈을 편하게 사용하기 위해서는 Python이 더 편할겁니다.\n",
    "\n",
    "- 제출형식은 pdf/html/doc/ppt 등 발표가 가능하면 괜찮습니다. 하지만 html로 주시면 가장 감사합니다.\n",
    "\n",
    "- 패키지 과제 발표는 세미나 쉬는시간 이후에 하게 되며, 역시 랜덤으로 5시00분에 발표됩니다.\n",
    "\n",
    "- 제출기한은 목요일 자정까지이며 지각시 벌금 5000원이 있습니다. 미제출 시 만원입니다. \n",
    "    - 패키지 2회 무단 미제출 시 퇴출이니 유의해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMModel,LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이번주에 다룰 내용은 머신러닝 모델의 해석/기본적인 딥러닝입니다.\n",
    "- 더불어서 다뤄지지는 내용은 randomness control입니다.\n",
    "- 먼저 주어진 코드를 실행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(learning_rate=0.3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test=  pd.read_csv('test.csv')\n",
    "\n",
    "train_x = train.drop(['price'], axis = 1)\n",
    "train_y = train.loc[:, ['price']]\n",
    "test_x = test.drop(['price'], axis = 1)\n",
    "test_y = np.sqrt(test.loc[:, ['price']])\n",
    "\n",
    "feature_list = list(train_x.columns)\n",
    "\n",
    "CBE_encoder = CatBoostEncoder()\n",
    "train_cbe = CBE_encoder.fit_transform(train_x[feature_list], train_y)\n",
    "test_cbe = CBE_encoder.transform(test_x[feature_list])\n",
    "\n",
    "best_lgbm_reg = LGBMRegressor(learning_rate = 0.3)\n",
    "best_lgbm_reg.fit(train_cbe, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Interpretable ML\n",
    "\n",
    "해석가능한 머신러닝은 모델의 결과를 해석하기 위한 방법들입니다. 보통 랜덤포레스트(Random Forest)에서 Feature(Variable) Importance에 대해 들어본 적이 있을텐데, 그것과 유사합니다. Interpretable ML 방법의 특징은 어떤 모델에도 다 적용이 가능하다는건데, SVM이나 Neural Net같이 해석이 불가능하다고 알려진 모델들도 어떤 변수들이 모델을 만드는데 있어서 주요하게 사용되었는지를 파악할 수 있게 해줍니다. 물론 회귀분석처럼 '다른 변수들을 고정시킨 상황에서 $x_1$이 한단위 증가하면 $y$가 평균적으로 $\\beta_1$만큼 증가한다' 라고 말할수는 없지만요!\n",
    "\n",
    "Feature Importance/Partial Dependence Plot/Lime/SHAP 에 대한 해석은 조금 조심해야할 필요가 있습니다. 밑의 링크의 '모델해석 및 이탈원인 분석'을 참고하면 되는데, 처음에 딱 이해하기 쉬운 개념은 아니지만 나중에 보다보면 더 이해가 잘 되실 것 같아요.\n",
    "\n",
    "https://danbi-ncsoft.github.io/competition/2019/02/19/big-contest-2018-retrospect.html\n",
    "\n",
    "나중에 관심있으시면 이 책을 보는 것을 추천드립니다. 저도 아직 안봄 ㅎ\n",
    "\n",
    "https://christophm.github.io/interpretable-ml-book/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **오늘의 해석은 각각 방법에 입각해서 엄밀하게 해석할 필요없이, 그냥 가볍게 해석해주시면 됩니다!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 모델 불러오기\n",
    "\n",
    "주어진 패키지를 불러오고, `lgbm.pkl`을 불러오세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature Importance 확인과 해석\n",
    "\n",
    "- 불러온 모델에 대해 `plot_importance`함수를 통해 Feature Importance를 시각화해주세요.\n",
    "- 결과에 대해 간단히 해석해주세요.\n",
    "\n",
    "여기서 Feature Importance는 Permutation를 통한 중요도를 보는 것이 아니고, tree 모델 자체의 구성에서 어떤 변수가 지니불순도를 잘 줄였는지를 확인한 것이라고 이해해주시면 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**이제는 불러온 모델 말고, `best_lgbm_reg`를 사용하세요.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Randomness Control\n",
    "\n",
    "- `random, numpy` 패키지의 난수를 42로 고정하세요.\n",
    "- 더불어서 `os` 패키지의 난수도 고정해야합니다.\n",
    "\n",
    "Permutation 방식의 Feature Importance를 시행한건데, permutation자체에 랜덤성이 있다보니 결과가 재현 가능하도록 시드를 고정해줍니다.\n",
    "\n",
    "파이썬의 시드 고정은 R처럼 그냥 `set.seed()`한다고 해서 고정되지 않습니다. 전체 파이썬과 여러 패키지들의 randomness를 각각 고정해주어야 재현가능해집니다. 정말 귀찮고, 딥러닝의 경우 GPU를 사용할 경우 GPU의 계산과 관련된 시드를 고정하면 속도가 상당히 느려진다고 알려져 있습니다. 더불어서 재현도 100%되진 않으며 성능도 살짝 떨어진다고는 하지만, GPU를 사용하지 않는 경우에는 문제가 없고 최소한 할줄은 알아야겠죠?\n",
    "\n",
    "더불어서 왜 저런식으로 복잡하게 구성이 되는가?에 대해 궁금할 수 있는데 찾아본 적은 없지만 아마도 `numpy`는 c++가 뒤에서 연산을 해주는 것으로 알고있고(그래서 빠름!), `random`은 그냥 파이썬이고, `os`는 우리 os를 건드리는 것이 아닐까....? 추측입니다 :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Permutation Feature Importance\n",
    "\n",
    "- permutation feature importance를 계산하기 위해 `best_lgbm_reg`를 `permutation_importance`함수를 사용해 test set에 적합하세요.\n",
    "- permutation feature importance를 시각화해주세요.\n",
    "\n",
    "위의 1.2에서는 train에서 변수중요도를 보고, 지금은 test에서 봐서 좀 이상하다고 생각할수도 있습니다. 편의를 위해, 그리고 실제로 변수중요도에 대한 부분에서 어떤 set에 대해 봐야하는지가 100% 정답처럼 있는 것은 아니라고 알고 있어요.(물론 제가 틀렸을수도!) 아무튼 너무 신경쓰지말고 해주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 SHAP(SHapley Additive exPlanations)의 확인과 해석\n",
    "\n",
    "- SHAP Value를 구하고 간단한 해석을 해주세요.\n",
    "- `shap.TreeExplainer`, `shap_values`, `shap.summary_plot` 정도의 함수만 사용하면 됩니다.\n",
    "- 결과가 좀 다른건 상관없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\namtaek\\anaconda3\\lib\\site-packages (0.39.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\namtaek\\anaconda3\\lib\\site-packages (from shap) (1.2.4)\n",
      "Requirement already satisfied: tqdm>4.25.0 in c:\\users\\namtaek\\anaconda3\\lib\\site-packages (from shap) (4.59.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\namtaek\\anaconda3\\lib\\site-packages (from shap) (1.19.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\namtaek\\anaconda3\\lib\\site-packages (from shap) (1.6.2)\n",
      "Requirement already satisfied: numba in c:\\users\\namtaek\\anaconda3\\lib\\site-packages (from shap) (0.53.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\namtaek\\anaconda3\\lib\\site-packages (from shap) (1.6.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in c:\\users\\namtaek\\anaconda3\\lib\\site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\namtaek\\anaconda3\\lib\\site-packages (from shap) (0.24.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\namtaek\\anaconda3\\lib\\site-packages (from numba->shap) (52.0.0.post20210125)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in c:\\users\\namtaek\\anaconda3\\lib\\site-packages (from numba->shap) (0.36.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\namtaek\\anaconda3\\lib\\site-packages (from pandas->shap) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\namtaek\\anaconda3\\lib\\site-packages (from pandas->shap) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\namtaek\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\namtaek\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\namtaek\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 딥러닝 기본\n",
    "\n",
    "딥러닝 정말 간단히 해볼겁니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 주어진 코드를 실행하고, 현재 신경망의 구조에 대해 간단히 설명해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train_x = train.drop(['price'], axis = 1)\n",
    "train_y = train.loc[:, ['price']]\n",
    "\n",
    "val_x = train_x[train['transaction_year'] == 4]\n",
    "val_y = train_y[train['transaction_year'] == 4]\n",
    "train_tune_x = train_x[train['transaction_year'] < 4]\n",
    "train_tune_y = train_y[train['transaction_year'] < 4]\n",
    "\n",
    "CBE_encoder = CatBoostEncoder()\n",
    "train_tune_cbe = CBE_encoder.fit_transform(train_tune_x[feature_list], train_tune_y)\n",
    "val_cbe = CBE_encoder.transform(val_x[feature_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(256, activation='relu', input_shape=[len(train_tune_cbe.keys())]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.0001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               2304      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 20,865\n",
      "Trainable params: 20,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 training loss와 validation loss를 시각화하세요.\n",
    "\n",
    "- 본인 컴에서 돌리면 꽤나 돌아갈수도 있어요. 주분과 함께하려면 패키지가 코랩으로 가거나, 주분이 코랩으로 가면 한번에 투 컴을 돌릴 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_tune_cbe, train_tune_y, epochs=300, validation_data = (val_cbe, val_y), batch_size = 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 어떤문제가 발생했는지 설명해주세요.\n",
    "\n",
    "- 꼭 써주세요.\n",
    "\n",
    "힌트\n",
    "\n",
    "- 이전에 lgbm 같은 경우 validation mse가 $1.2 * 10^8$ 이였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 더 좋은 성능의 딥러닝 모델을 위해\n",
    "\n",
    "- test set에 대해 딥러닝 모형의 성능을 평가하세요.\n",
    "- dense 조절, batch_size 조절, regularization, dropout, batch normalization 등의 방법을 활용해 최고의 성능을 얻어보세요.\n",
    "- 만약 성능의 향상이 어렵다면, 다양한 방법들을 시도하는 것을 목표로 해주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = list(train_x.columns)\n",
    "\n",
    "CBE_encoder = CatBoostEncoder()\n",
    "train_cbe = CBE_encoder.fit_transform(train_x[feature_list], train_y)\n",
    "test_cbe = CBE_encoder.transform(test_x[feature_list])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
