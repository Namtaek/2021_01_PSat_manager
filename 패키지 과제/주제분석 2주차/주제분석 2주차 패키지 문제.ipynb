{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21-01 주제분석 2주차 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주제분석 2주차 분석 툴은 Python/R 둘 다 가능합니다. \n",
    "    - 1-3주차 패키지 문제의 조건 및 힌트는 Python을 기준으로 하지만, R을 사용해도 무방합니다.\n",
    "    - 다만 2/3주차의 머신러닝/딥러닝 모듈을 편하게 사용하기 위해서는 Python이 더 편할겁니다.\n",
    "\n",
    "- 제출형식은 pdf/html/doc/ppt 등 발표가 가능하면 괜찮습니다. 하지만 html로 주시면 가장 감사합니다.\n",
    "\n",
    "- 패키지 과제 발표는 세미나 쉬는시간 이후에 하게 되며, 역시 랜덤으로 5시00분에 발표됩니다.\n",
    "\n",
    "- 제출기한은 목요일 자정까지이며 지각시 벌금 5000원이 있습니다. 미제출 시 만원입니다. \n",
    "    - 패키지 2회 무단 미제출 시 퇴출이니 유의해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이번주에 다룰 내용은 test_set분리/릿지회귀/LGBM입니다.\n",
    "- 더불어서 다뤄지지는 내용은 data leakage 방지(test set 사용하지 않기), 하이퍼 파라미터 튜닝 방법입니다.\n",
    "- 최대한 생각할 수 있는 여지들을 넣으려고 했습니다.\n",
    "    - 데이터분석을 할 때 언제나 고민하고 생각하면서 해야 불필요한 삽질을 안할 수 있습니다.\n",
    "    - 더불어서 주제분석/공모전 때 중요한건 fancy한 모델을 썼느냐 아니냐보다 논리와 결과에 대한 해석입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 데이터 불러오기\n",
    "\n",
    "`trian.csv`와 `test.csv`를 불러오세요.\n",
    "\n",
    "- train은 `transaction_year`가 5 미만인 경우,\n",
    "- test는  `transaction_year`가 5인 경우입니다. 알아두시면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 단위 수정\n",
    "\n",
    "- x와 y도 분리해두세요.\n",
    "- train에만 일단 적용해주세요. 우린 아직 test데이터를 보지 못했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 validation set 분할 - 첫번째\n",
    "\n",
    "- 사이킷런의 train_test_split을 통해 train데이터를 8:2로 validation set을 만들어주세요.\n",
    "- 즉 train중에서 train/val이 있고, test set이 따로 존재합니다.\n",
    "- test set은 전처리 과정에서 절대 사용되지 않을 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 질문\n",
    "\n",
    "- 이렇게 데이터를 나눌 경우 어떤 문제가 발생할 수 있을까요?\n",
    "    - 힌트) 현재 데이터는 관측된 시간이 존재합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 validation set 분할 - 두번째\n",
    "\n",
    "- `transaction_year == 4`인  행을 validation으로 지정해서 분할하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 캣부스트 인코딩 전에\n",
    "\n",
    "- 일단 캣부스트 인코딩을 위해 다음을 설치하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in c:\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\anaconda3\\lib\\site-packages (from category_encoders) (1.5.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\anaconda3\\lib\\site-packages (from category_encoders) (0.11.1)\n",
      "Requirement already satisfied: pandas>=0.21.1 in c:\\anaconda3\\lib\\site-packages (from category_encoders) (1.1.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\anaconda3\\lib\\site-packages (from category_encoders) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\anaconda3\\lib\\site-packages (from category_encoders) (1.18.5)\n",
      "Requirement already satisfied: six in c:\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.cat_boost import CatBoostEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 캣부스트 인코딩\n",
    "\n",
    "- 방금까지 trainset을 분할했죠? 그 분할된 것을 캣부스트 인코딩의 인자로 받을 겁니다.\n",
    "- train에서 분할된 train을 인코딩을 위한 학습으로 사용해서, 이를 validation_x에 적용합니다.\n",
    "- 해당 결과를 `head()`를 통해 보여주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dong</th>\n",
       "      <th>apt</th>\n",
       "      <th>exclusive_use_area</th>\n",
       "      <th>floor</th>\n",
       "      <th>transaction_year</th>\n",
       "      <th>until_trans</th>\n",
       "      <th>sin_date</th>\n",
       "      <th>cos_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>89176.597368</td>\n",
       "      <td>86280.203194</td>\n",
       "      <td>107.91</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>89176.597368</td>\n",
       "      <td>86280.203194</td>\n",
       "      <td>151.81</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>89176.597368</td>\n",
       "      <td>86280.203194</td>\n",
       "      <td>94.51</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>89176.597368</td>\n",
       "      <td>86280.203194</td>\n",
       "      <td>94.28</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>103789.156533</td>\n",
       "      <td>107170.755379</td>\n",
       "      <td>145.96</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dong            apt  exclusive_use_area  floor  \\\n",
       "2451   89176.597368   86280.203194              107.91     14   \n",
       "2452   89176.597368   86280.203194              151.81     10   \n",
       "2453   89176.597368   86280.203194               94.51      2   \n",
       "2454   89176.597368   86280.203194               94.28     12   \n",
       "2455  103789.156533  107170.755379              145.96     13   \n",
       "\n",
       "      transaction_year  until_trans      sin_date      cos_date  \n",
       "2451                 4            9 -1.000000e+00 -1.836970e-16  \n",
       "2452                 4            9 -1.000000e+00 -1.836970e-16  \n",
       "2453                 4            9 -2.449294e-16  1.000000e+00  \n",
       "2454                 4            9 -2.449294e-16  1.000000e+00  \n",
       "2455                 4           13 -1.000000e+00 -1.836970e-16  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_cbe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 릿지 회귀 (Ridge Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 성능이 좋다고 알려진 부스팅모델 두개 하려다가, 그냥 릿지로 선회했습니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 상관계수 플랏\n",
    "\n",
    "- 캣부스트 인코딩을 시행한 튜닝을 위한 trainset에 대해 상관계수플랏을 그리세요.\n",
    "- 해석해주세요. 릿지 회귀가 잘 작동할까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 해석과 무관하게 일단 릿지 튜닝\n",
    "\n",
    "- mse를 비교해서 튜닝을 진행하세요.\n",
    "- 릿지의 튜닝파라미터 알파는 0.00001, 0.0001, 0.001, 0.01, 0.1로 설정합니다.\n",
    "- 알파가 클수록 강한 페널티입니다.\n",
    "- 튜닝결과를 시각화해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 튜닝결과 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 해석\n",
    "\n",
    "튜닝 결과에 대한 플랏을 보고 해석을 해주세요.\n",
    "\n",
    "- 튜닝이 잘되었나요?\n",
    "- 튜닝이 안되었다면 그 이유는 무엇인가요?\n",
    "\n",
    "- https://stats.stackexchange.com/questions/81395/relationship-between-ridge-regression-and-pca-regression\n",
    "    - 수식이 쉽진 않을텐데 그냥 슬쩍 보세요...ㅎㅎㅎ\n",
    "- https://online.stat.psu.edu/stat508/lesson/5/5.1\n",
    "    - penn state자료는 맨 아래부분만 보면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 그냥 선형 모형으로!\n",
    "\n",
    "그냥 linear regression을 튜닝을 위한 trainset에 적합시키고, validation set에 대한 rmse를 계산하세요.\n",
    "\n",
    "- linear regression은 다른 튜닝 파라미터를 필요로하지 않습니다.\n",
    "- ridge와의 validation rmse를 비교했을 때, 어떤 모형을 쓰는 것이 나을지 말해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LightGBM\n",
    "\n",
    "강력하면서도 빠른 부스팅 모형인 LGBM에 대해 다룰 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\anaconda3\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\anaconda3\\lib\\site-packages (from lightgbm) (0.23.1)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from lightgbm) (1.18.5)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from lightgbm) (1.5.0)\n",
      "Requirement already satisfied: wheel in c:\\anaconda3\\lib\\site-packages (from lightgbm) (0.34.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 LightGBM 이해\n",
    "\n",
    "모형에 대해 아주 기본적인 이해는 필요하겠죠? LGBM의 특징/장점/문제점을 적어주세요.\n",
    "\n",
    "- 20-01 데마팀 클린업 3주차 혹은 또 다른 데마팀 클린업을 보셔도 괜찮습니다.\n",
    "- 구글링해도 잘 나옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 LGBM 튜닝\n",
    "\n",
    "- LGBM의 튜닝파라미터는 많습니다.\n",
    "- `max_depth`, `learning_rate`, `lambda`, `min_child_samples` 등 다양한데, 패키지에서는 learning rate만 튜닝하도록 하겠습니다.\n",
    "    - [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 0.99] 이렇게 튜닝해주세요.\n",
    "    - 부스팅에서는 일단 learning rate과 iteration의 trade off를 적절하게 고려해줘서 학습속도를 맞춰준다음, 세부적인 튜닝을 하는게 일반적입니다.\n",
    "- 더하고 싶으면 해서 더 좋은 성능을 내셔도 됩니다! 보통 `enumerate`를 통해 파라미터를 묶어줘서 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMModel,LGBMRegressor\n",
    "# import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 튜닝결과 시각화\n",
    "\n",
    "learning_rate의 변화에 따른 rmse의 변화를 시각화해주세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 튜닝에 대하여 알아보자\n",
    "\n",
    "우리가 한 튜닝방식은 `그리드 서치(Grid Search)`방법입니다. 다른 방법으로는 `Random Search`와 `Bayesian Optimization` 방법이 있습니다.\n",
    "\n",
    "- 세 가지 방법에 대해서 간단히 설명하고, 장단점을 말해주세요.\n",
    "- 요즘에는 Neural Process 기반의 Optimization이란 방법도 활발히 연구중이라던데...그냥 그렇다구요 ㅎㅎㅎ 원래 Bayesian Optimization이 Gaussian Process 기반인데, 이걸 뛰어넘는 성능이래요 암튼~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 test set 불러오기\n",
    "\n",
    "- test set을 불러오고\n",
    "- X와 y를 분리하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 캣부스트 인코딩\n",
    "\n",
    "- 전체 train set에 대해 캣부스트 인코딩을 시행해주세요.\n",
    "- 인자에는 train_x/train_y/test_x가 들어갈겁니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 최적의 파라미터 적합\n",
    "\n",
    "- 2와 3의 결과에서 최적의 파라미터(모델)을 전체 trainset에 대해 적합하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 test set에 대해 평가\n",
    "\n",
    "- 두 모델을 test set에 대해 평가해서 비교하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
